model:
  base_learning_rate: 6e-5
  target: ldm.models.autoencoder.VQModel

  params:
    n_embed: 8192
    embed_dim: 8
    monitor: val/rec_loss

    ddconfig:
      in_channels: 1
      out_channels: 1
      ch: 32
      resolution: 128
      attn_resolutions: [8]
      ch_mult: [1,2,4]    # num_down = len(ch_mult)-1
      num_blocks: 2
      z_channels: 4
      block_type: "ResnetBlock"    # ResnetBlock, ConvnetBlock
      attn_type: "vanilla"    # to be continued
      dropout: 0.0
      resamp_with_conv: true
      num_groups: 8
    lossconfig:
      target: ldm.modules.losses.VQLPIPSWithDiscriminator
      params:
        disc_start: 100000
        codebook_weight: 1.2
        disc_in_channels: 1
        disc_num_layers: 4
        disc_ndf: 48
        disc_factor: 0.8
        disc_weight: 0.3
        ct_disc_weight: 0.8
        perceptual_weight: 0
        use_actnorm: true
        pixel_loss: "l1"

data:
  batch_size: 1
  root_data: F:/Data_Space/Pelvic1K/processed_128x128_s2.0_block_48
  train_files_name: ./files_name/train_pelvic_2d_256_2.0_3d_128_2.5.txt
  test_files_name: ./files_name/test_pelvic_2d_256_2.0_3d_128_2.5.txt
  num_workers: 1
  pin_memory: True
